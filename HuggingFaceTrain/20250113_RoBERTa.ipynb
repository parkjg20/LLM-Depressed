{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ca2182-0c85-4624-8e1e-c5e4e69a7b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:54:27.038437Z",
     "iopub.status.busy": "2025-01-13T06:54:27.037463Z",
     "iopub.status.idle": "2025-01-13T06:54:30.175726Z",
     "shell.execute_reply": "2025-01-13T06:54:30.174669Z",
     "shell.execute_reply.started": "2025-01-13T06:54:27.038337Z"
    }
   },
   "outputs": [],
   "source": [
    "# 코드 -> 텍스트 매핑 생성\n",
    "map_age_band = {'A01': '청소년', 'A02': '청년', 'A03': '중년', 'A04': '노년'}\n",
    "map_gender = {'G01': '남성', 'G02': '여성'}\n",
    "\n",
    "# 상황 매핑\n",
    "map_situation = {\n",
    "    \"S01\": \"가족관계\",\n",
    "    \"S02\": \"학업 및 진로\",\n",
    "    \"S03\": \"학교폭력/따돌림\",\n",
    "    \"S04\": \"대인관계\",\n",
    "    \"S05\": \"연애,결혼,출산\",\n",
    "    \"S06\": \"진로,취업,직장\",\n",
    "    \"S07\": \"대인관계(부부, 자녀)\",\n",
    "    \"S08\": \"재정,은퇴,노후준비\",\n",
    "    \"S09\": \"건강\",\n",
    "    \"S10\": \"직장, 업무 스트레스\",\n",
    "    \"S11\": \"건강,죽음\",\n",
    "    \"S12\": \"대인관계(노년)\",\n",
    "    \"S13\": \"재정\",\n",
    "    \"S14\": \"기타\"\n",
    "}\n",
    "\n",
    "# 질병 매핑\n",
    "map_disease = {\n",
    "    \"D01\": \"만성질환 유\",\n",
    "    \"D02\": \"만성질환 무\"\n",
    "}\n",
    "\n",
    "# 감정 매핑\n",
    "map_emotion = {\n",
    "    \"E10\": \"분노\",\n",
    "    \"E20\": \"슬픔\",\n",
    "    \"E30\": \"불안\",\n",
    "    \"E60\": \"기쁨\"\n",
    "}\n",
    "\n",
    "map_code = {\n",
    "    'age_band': map_age_band,\n",
    "    'gender': map_gender,\n",
    "    'situation': map_situation,\n",
    "    'disease': map_disease,\n",
    "    'emotion': map_emotion\n",
    "}\n",
    "\n",
    "def decode(code_type, code):\n",
    "     return map_code[code_type][code]\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_json('../dataset.json')\n",
    "validation_dataset = pd.read_json('../filtered_validation_dataset.json')\n",
    "\n",
    "filtered_dataset = dataset # 필터링 생략\n",
    "\n",
    "flattened_profile = pd.json_normalize(filtered_dataset['profile'])\n",
    "flattened_talk = pd.json_normalize(filtered_dataset['talk'])\n",
    "\n",
    "combine = flattened_profile.join(flattened_talk)\n",
    "df = pd.DataFrame(combine)\n",
    "\n",
    "# 감정 레이블 간소화\n",
    "df[\"emotion_type\"] = df[\"emotion.type\"].str[:2] + \"0\"\n",
    "\n",
    "# 6가지 카테고리로 간소화\n",
    "df[\"emotion_type\"] = df[\"emotion_type\"].apply(lambda x: 'E20' if (x.strip() == 'E40') else x) # 정확도를 위해 4가지로 축소(상처 -> 슬픔)\n",
    "df[\"emotion_type\"] = df[\"emotion_type\"].apply(lambda x: 'E30' if (x.strip() == 'E50') else x) # 정확도를 위해 4가지로 축소(당황 -> 불안)\n",
    "df['emotion_label'] = df['emotion_type'].astype('category').cat.codes\n",
    "label_mapping = dict(enumerate(df['emotion_type'].astype('category').cat.categories))\n",
    "label_to_code_map = {value: key for key, value in label_mapping.items()}\n",
    "\n",
    "# print(label_to_code_map)\n",
    "\n",
    "val_df = pd.DataFrame(validation_dataset)\n",
    "val_df[\"emotion_type\"] = val_df[\"emotion.type\"].apply(lambda x: 'E20' if (x.strip() == 'E40') else x) # 정확도를 위해 4가지로 축소(상처 -> 슬픔)\n",
    "val_df[\"emotion_type\"] = val_df[\"emotion_type\"].apply(lambda x: 'E30' if (x.strip() == 'E50') else x) # 정확도를 위해 4가지로 축소(당황 -> 불안)\n",
    "val_df['emotion_label'] = val_df['emotion_type'].apply(lambda x: label_to_code_map[x])\n",
    "\n",
    "df = df.drop(columns=[\n",
    "    'persona-id',\n",
    "    'persona.persona-id',\n",
    "    'persona.computer',\n",
    "    'emotion.emotion-id',\n",
    "    'id.profile-id',\n",
    "    'id.talk-id',\n",
    "    'content.SS01',\n",
    "    'content.SS02',\n",
    "    'content.SS03'\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63cb87d-dc93-4e5c-91db-ef9921ea201b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T06:54:30.177572Z",
     "iopub.status.busy": "2025-01-13T06:54:30.177326Z",
     "iopub.status.idle": "2025-01-13T06:54:57.934208Z",
     "shell.execute_reply": "2025-01-13T06:54:57.931595Z",
     "shell.execute_reply.started": "2025-01-13T06:54:30.177546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tokenize_function() got an unexpected keyword argument 'batched'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 데이터셋 토크나이징\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m tokenized_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# DataLoader 생성\u001b[39;00m\n\u001b[1;32m     18\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:10468\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:10466\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/gatoai/python/venv/jupyter-4.3.4-py3.10/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tokenize_function() got an unexpected keyword argument 'batched'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "# 사전 학습된 모델과 토크나이저 로드\n",
    "model_name = \"klue/roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# 데이터셋 토크나이징\n",
    "tokenized_datasets = df.map(tokenize_function, batched=True)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=8)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 학습률 스케줄러 설정\n",
    "num_training_steps = len(train_dataloader) * 3  # Epoch 수\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 모델 학습 모드\n",
    "model.train()\n",
    "\n",
    "# 손실 함수\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 루프\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "for epoch in range(3):  # Epoch 수\n",
    "    for batch in train_dataloader:\n",
    "        # 입력 데이터 준비\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key in tokenizer.model_input_names}\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward Pass 및 옵티마이저 스텝\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # 진행 상태 업데이트\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ece33-7199-4729-a05b-e11434600df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_dataloader:\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key in tokenizer.model_input_names}\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "        total += len(batch[\"labels\"])\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.5.1 (py3.10)",
   "language": "python",
   "name": "pytorch-2.5.1-cuda12.4-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
