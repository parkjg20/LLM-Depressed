{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d85a31f4-4d18-4c78-ac58-3c076572e9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T10:42:53.082011Z",
     "iopub.status.busy": "2025-01-05T10:42:53.081085Z",
     "iopub.status.idle": "2025-01-05T10:42:54.753757Z",
     "shell.execute_reply": "2025-01-05T10:42:54.752999Z",
     "shell.execute_reply.started": "2025-01-05T10:42:53.081935Z"
    }
   },
   "outputs": [],
   "source": [
    "# 코드 -> 텍스트 매핑 생성\n",
    "map_age_band = {'A01': '청소년', 'A02': '청년', 'A03': '중년', 'A04': '노년'}\n",
    "map_gender = {'G01': '남성', 'G02': '여성'}\n",
    "\n",
    "# 상황 매핑\n",
    "map_situation = {\n",
    "    \"S01\": \"가족관계\",\n",
    "    \"S02\": \"학업 및 진로\",\n",
    "    \"S03\": \"학교폭력/따돌림\",\n",
    "    \"S04\": \"대인관계\",\n",
    "    \"S05\": \"연애,결혼,출산\",\n",
    "    \"S06\": \"진로,취업,직장\",\n",
    "    \"S07\": \"대인관계(부부, 자녀)\",\n",
    "    \"S08\": \"재정,은퇴,노후준비\",\n",
    "    \"S09\": \"건강\",\n",
    "    \"S10\": \"직장, 업무 스트레스\",\n",
    "    \"S11\": \"건강,죽음\",\n",
    "    \"S12\": \"대인관계(노년)\",\n",
    "    \"S13\": \"재정\",\n",
    "    \"S14\": \"기타\"\n",
    "}\n",
    "\n",
    "# 질병 매핑\n",
    "map_disease = {\n",
    "    \"D01\": \"만성질환 유\",\n",
    "    \"D02\": \"만성질환 무\"\n",
    "}\n",
    "\n",
    "# 감정 매핑\n",
    "map_emotion = {\n",
    "    \"E10\": \"분노\",\n",
    "    \"E20\": \"슬픔\",\n",
    "    \"E30\": \"불안\",\n",
    "    # \"E40\": \"상처\",\n",
    "    # \"E50\": \"당황\",\n",
    "    \"E60\": \"기쁨\",\n",
    "    # \"E10\": \"분노\",\n",
    "    # \"E11\": \"툴툴대는\",\n",
    "    # \"E12\": \"좌절한\",\n",
    "    # \"E13\": \"짜증내는\",\n",
    "    # \"E14\": \"방어적인\",\n",
    "    # \"E15\": \"악의적인\",\n",
    "    # \"E16\": \"안달하는\",\n",
    "    # \"E17\": \"구역질 나는\",\n",
    "    # \"E18\": \"노여워하는\",\n",
    "    # \"E19\": \"성가신\",\n",
    "    # \"E20\": \"슬픔\",\n",
    "    # \"E21\": \"실망한\",\n",
    "    # \"E22\": \"비통한\",\n",
    "    # \"E23\": \"후회되는\",\n",
    "    # \"E24\": \"우울한\",\n",
    "    # \"E25\": \"마비된\",\n",
    "    # \"E26\": \"염세적인\",\n",
    "    # \"E27\": \"눈물이 나는\",\n",
    "    # \"E28\": \"낙담한\",\n",
    "    # \"E29\": \"환멸을 느끼는\",\n",
    "    # \"E30\": \"불안\",\n",
    "    # \"E31\": \"두려운\",\n",
    "    # \"E32\": \"스트레스 받는\",\n",
    "    # \"E33\": \"취약한\",\n",
    "    # \"E34\": \"혼란스러운\",\n",
    "    # \"E35\": \"당혹스러운\",\n",
    "    # \"E36\": \"회의적인\",\n",
    "    # \"E37\": \"걱정스러운\",\n",
    "    # \"E38\": \"조심스러운\",\n",
    "    # \"E39\": \"초조한\",\n",
    "    # \"E40\": \"상처\",\n",
    "    # \"E41\": \"질투하는\",\n",
    "    # \"E42\": \"배신당한\",\n",
    "    # \"E43\": \"고립된\",\n",
    "    # \"E44\": \"충격 받은\",\n",
    "    # \"E45\": \"가난한, 불우한\",\n",
    "    # \"E46\": \"희생된\",\n",
    "    # \"E47\": \"억울한\",\n",
    "    # \"E48\": \"괴로워하는\",\n",
    "    # \"E49\": \"버려진\",\n",
    "    # \"E50\": \"당황\",\n",
    "    # \"E51\": \"고립된(당황한)\",\n",
    "    # \"E52\": \"남의 시선을 의식하는\",\n",
    "    # \"E53\": \"외로운\",\n",
    "    # \"E54\": \"열등감\",\n",
    "    # \"E55\": \"죄책감의\",\n",
    "    # \"E56\": \"부끄러운\",\n",
    "    # \"E57\": \"혐오스러운\",\n",
    "    # \"E58\": \"한심한\",\n",
    "    # \"E59\": \"혼란스러운(당황한)\",\n",
    "    # \"E60\": \"기쁨\",\n",
    "    # \"E61\": \"감사하는\",\n",
    "    # \"E62\": \"신뢰하는\",\n",
    "    # \"E63\": \"편안한\",\n",
    "    # \"E64\": \"만족스러운\",\n",
    "    # \"E65\": \"흥분\",\n",
    "    # \"E66\": \"느긋\",\n",
    "    # \"E67\": \"안도\",\n",
    "    # \"E68\": \"신이 난\",\n",
    "    # \"E69\": \"자신하는\"\n",
    "}\n",
    "\n",
    "map_code = {\n",
    "    'age_band': map_age_band,\n",
    "    'gender': map_gender,\n",
    "    'situation': map_situation,\n",
    "    'disease': map_disease,\n",
    "    'emotion': map_emotion\n",
    "}\n",
    "\n",
    "def decode(code_type, code):\n",
    "     return map_code[code_type][code]\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_json('./dataset.json')\n",
    "validation_dataset = pd.read_json('./filtered_validation_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c08b3697-4dfb-4372-8736-f2becb28fab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:40:04.513686Z",
     "start_time": "2024-12-24T02:40:04.474505Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T10:42:54.755318Z",
     "iopub.status.busy": "2025-01-05T10:42:54.754920Z",
     "iopub.status.idle": "2025-01-05T10:42:55.995819Z",
     "shell.execute_reply": "2025-01-05T10:42:55.995094Z",
     "shell.execute_reply.started": "2025-01-05T10:42:54.755291Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# 데이터 전처리\n",
    "########################################\n",
    "# 연령(profile.persona.human[0]) - [A01: 청소년, A02: 청년, A03: 중년, A04: 노년] \n",
    "# 성별(profile.persona.human[1]) - [G01: 남성, G02: 여성]\n",
    "\n",
    "# 'human' 리스트에 'A01'이 포함된 레코드 필터링\n",
    "# filtered_dataset = dataset[\n",
    "#     dataset['profile'].apply(lambda x: 'A01' in x['persona']['human'])\n",
    "# ]\n",
    "\n",
    "# 필터링 생략\n",
    "filtered_dataset = dataset\n",
    "\n",
    "flattened_profile = pd.json_normalize(filtered_dataset['profile'])\n",
    "flattened_talk = pd.json_normalize(filtered_dataset['talk'])\n",
    "\n",
    "combine = flattened_profile.join(flattened_talk)\n",
    "df = pd.DataFrame(combine)\n",
    "\n",
    "# 감정 레이블 간소화\n",
    "df[\"emotion_type\"] = df[\"emotion.type\"].str[:2] + \"0\"\n",
    "\n",
    "# 6가지 카테고리로 간소화\n",
    "df[\"emotion_type\"] = df[\"emotion_type\"].apply(lambda x: 'E20' if (x.strip() == 'E40') else x) # 정확도를 위해 4가지로 축소(상처 -> 슬픔)\n",
    "df[\"emotion_type\"] = df[\"emotion_type\"].apply(lambda x: 'E30' if (x.strip() == 'E50') else x) # 정확도를 위해 4가지로 축소(당황 -> 불안)\n",
    "df['emotion_label'] = df['emotion_type'].astype('category').cat.codes\n",
    "label_mapping = dict(enumerate(df['emotion_type'].astype('category').cat.categories))\n",
    "label_to_code_map = {value: key for key, value in label_mapping.items()}\n",
    "\n",
    "# print(label_to_code_map)\n",
    "\n",
    "val_df = pd.DataFrame(validation_dataset)\n",
    "val_df[\"emotion_type\"] = val_df[\"emotion.type\"].apply(lambda x: 'E20' if (x.strip() == 'E40') else x) # 정확도를 위해 4가지로 축소(상처 -> 슬픔)\n",
    "val_df[\"emotion_type\"] = val_df[\"emotion_type\"].apply(lambda x: 'E30' if (x.strip() == 'E50') else x) # 정확도를 위해 4가지로 축소(당황 -> 불안)\n",
    "val_df['emotion_label'] = val_df['emotion_type'].apply(lambda x: label_to_code_map[x])\n",
    "\n",
    "# 긍정 0, 부정 1로 간소화\n",
    "# df[\"emotion_label\"] = df[\"emotion_type\"].apply(lambda x: 0 if x == 'E60' else 1) # 긍/부정 두가지 감정으로 범주화\n",
    "# label_mapping = { 0: '긍정', 1: '부정' }\n",
    "# label_to_code_map = { '긍정': 0, '부정': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35666d94-bdcf-48a4-9e01-4f62ad3dfcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:48:52.481600Z",
     "start_time": "2024-12-24T02:48:52.475837Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T10:42:55.997286Z",
     "iopub.status.busy": "2025-01-05T10:42:55.996815Z",
     "iopub.status.idle": "2025-01-05T10:42:57.512684Z",
     "shell.execute_reply": "2025-01-05T10:42:57.511892Z",
     "shell.execute_reply.started": "2025-01-05T10:42:55.997258Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 데이터 로드 및 전처리\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        text = f\"[CLS]{decode('situation', row['emotion.situation'][0])}[SEP]{decode('age_band', row['persona.human'][0])}[SEP]{row['content.HS01']} {row['content.HS02']} {row['content.HS03']}\".strip()\n",
    "        label = row['emotion_label']\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 2. 모델 및 토크나이저 로드\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-base\"\n",
    "# MODEL_NAME = \"klue/roberta-small\"\n",
    "# MODEL_NAME = \"klue/roberta-large\"\n",
    "# MODEL_NAME = \"beomi/kcbert-base\"\n",
    "# MODEL_NAME = \"skt/kobert-base-v1\"\n",
    "# MODEL_NAME = \"beomi/KcELECTRA-base\"\n",
    "# MODEL_NAME = \"mental/mental-roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 데이터셋 생성\n",
    "MAX_LEN = 128\n",
    "\n",
    "### 별도의 데이터셋 사용\n",
    "train_dataset = Dataset(df, tokenizer, MAX_LEN)\n",
    "val_dataset = Dataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "# 별도의 데이터셋 사용\n",
    "\n",
    "### 학습 셋을 나눠서 사용\n",
    "# data_train, data_val = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_dataset = Dataset(data_train, tokenizer, MAX_LEN)\n",
    "# val_dataset = Dataset(data_val, tokenizer, MAX_LEN)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "# 학습 셋을 나눠서 사용\n",
    "\n",
    "# 3. 모델 초기화\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=df['emotion_label'].nunique(),\n",
    "    hidden_dropout_prob=0.3,  # Dropout 비율 증가\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 4. 손실 함수 및 옵티마이저 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(df['emotion_label']), \n",
    "    y=df['emotion_label']\n",
    ")\n",
    "weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e1c9078-9330-4486-b305-b1d4bd54bd36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:56:11.411428Z",
     "start_time": "2024-12-24T02:56:11.406521Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T10:42:57.514398Z",
     "iopub.status.busy": "2025-01-05T10:42:57.513993Z",
     "iopub.status.idle": "2025-01-05T10:42:57.523333Z",
     "shell.execute_reply": "2025-01-05T10:42:57.522004Z",
     "shell.execute_reply.started": "2025-01-05T10:42:57.514371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. 학습 루프\n",
    "from transformers import get_scheduler\n",
    "\n",
    "EPOCHS = 5\n",
    "num_training_steps = len(train_loader) * EPOCHS\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(data_loader), classification_report(true_labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "230da2d5-9aac-421b-90b4-85c67b24e1c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T02:57:19.079863Z",
     "start_time": "2024-12-24T02:56:18.280353Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-05T10:42:57.525126Z",
     "iopub.status.busy": "2025-01-05T10:42:57.524626Z",
     "iopub.status.idle": "2025-01-05T11:34:32.980798Z",
     "shell.execute_reply": "2025-01-05T11:34:32.979038Z",
     "shell.execute_reply.started": "2025-01-05T10:42:57.525080Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.7729\n",
      "Validation Loss: 0.8890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.44      0.54       516\n",
      "           1       0.59      0.74      0.65       553\n",
      "           2       0.64      0.68      0.66       493\n",
      "           3       0.65      0.97      0.78        62\n",
      "\n",
      "    accuracy                           0.63      1624\n",
      "   macro avg       0.65      0.71      0.66      1624\n",
      "weighted avg       0.65      0.63      0.62      1624\n",
      "\n",
      "Epoch 2/5\n",
      "Train Loss: 0.6310\n",
      "Validation Loss: 0.9054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60       516\n",
      "           1       0.63      0.71      0.66       553\n",
      "           2       0.68      0.67      0.67       493\n",
      "           3       0.61      0.97      0.75        62\n",
      "\n",
      "    accuracy                           0.65      1624\n",
      "   macro avg       0.64      0.72      0.67      1624\n",
      "weighted avg       0.65      0.65      0.65      1624\n",
      "\n",
      "Epoch 3/5\n",
      "Train Loss: 0.5890\n",
      "Validation Loss: 0.9236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59       516\n",
      "           1       0.63      0.70      0.66       553\n",
      "           2       0.62      0.67      0.65       493\n",
      "           3       0.61      0.97      0.75        62\n",
      "\n",
      "    accuracy                           0.64      1624\n",
      "   macro avg       0.64      0.71      0.66      1624\n",
      "weighted avg       0.65      0.64      0.64      1624\n",
      "\n",
      "Epoch 4/5\n",
      "Train Loss: 0.5626\n",
      "Validation Loss: 0.9608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58       516\n",
      "           1       0.63      0.70      0.66       553\n",
      "           2       0.62      0.67      0.65       493\n",
      "           3       0.57      0.97      0.71        62\n",
      "\n",
      "    accuracy                           0.64      1624\n",
      "   macro avg       0.63      0.71      0.65      1624\n",
      "weighted avg       0.65      0.64      0.63      1624\n",
      "\n",
      "Epoch 5/5\n",
      "Train Loss: 0.5436\n",
      "Validation Loss: 1.0144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56       516\n",
      "           1       0.59      0.73      0.65       553\n",
      "           2       0.64      0.63      0.64       493\n",
      "           3       0.52      0.97      0.68        62\n",
      "\n",
      "    accuracy                           0.62      1624\n",
      "   macro avg       0.61      0.70      0.63      1624\n",
      "weighted avg       0.64      0.62      0.62      1624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 6. 학습 및 평가 실행\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_report = eval_model(model, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(val_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccdcb43b-7586-45ca-a113-87fc8ff00d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T08:03:51.242636Z",
     "iopub.status.busy": "2025-01-05T08:03:51.241656Z",
     "iopub.status.idle": "2025-01-05T08:03:52.574804Z",
     "shell.execute_reply": "2025-01-05T08:03:52.573187Z",
     "shell.execute_reply.started": "2025-01-05T08:03:51.242557Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7. 모델 저장\n",
    "torch.save(model.state_dict(), 'EXP1_RoBERTa.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e81079-d0dd-4c26-8fbe-2084ae159d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.5.1 (py3.10)",
   "language": "python",
   "name": "pytorch-2.5.1-cuda12.4-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
